
Multi-agent scenarios can be simulated by game theoretic decision trees.

Even in the case of perfectly aligned agents the only stable outcome might be bad.

We can use classic game theory but we can also deal with scenarios which are not intuitive for humans, e.g. replying 1000 times the decision with some rule, [[Deep Forgetting]], etc.
